---
id: chapter4-index
title: Overview
---

## Chapter 4: Sensing and Perception

For a humanoid robot to interact intelligently and safely with its environment, it must first be able to perceive it. This chapter explores the diverse array of sensors that equip humanoid robots with awareness, both of their own internal state and of the external world. We will categorize sensors into proprioceptive (internal) and exteroceptive (external) types, delving into the principles of operation for joint encoders, IMUs, force/torque sensors, LiDAR, stereo cameras, and more. Beyond individual sensors, the chapter will cover crucial topics like tactile and auditory perception, and how data from multiple sensors can be intelligently combined through sensor fusion techniques. Finally, we will introduce fundamental computer vision concepts, which are vital for interpreting visual data and enabling higher-level understanding of the robot's surroundings. A strong understanding of sensing and perception is the bedrock upon which intelligent robotic behavior is built.

**Sections in this chapter:**

*   [4.1 Proprioception: Joint Encoders, IMUs, Force/Torque Sensors](./sections/4.1-proprioception.md)
*   [4.2 Exteroception: Lidar, Stereo Vision, RGB-D Cameras](./sections/4.2-exteroception.md)
*   [4.3 Tactile Sensing: Pressure, Slip, and Proximity](./sections/4.3-tactile-sensing.md)
*   [4.4 Auditory Perception: Microphones and Sound Localization](./sections/4.4-auditory-perception.md)
*   [4.5 Sensor Fusion: Kalman Filters and Probabilistic Approaches](./sections/4.5-sensor-fusion.md)
*   [4.6 Computer Vision Fundamentals for Humanoids](./sections/4.6-computer-vision-fundamentals.md)
